% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\author{}
\date{\vspace{-2.5em}}

\begin{document}

\hypertarget{simulation-controlling-underlying-data-generation-process}{%
\subsection{Simulation Controlling Underlying Data Generation Process}\label{simulation-controlling-underlying-data-generation-process}}

The fully simulated data simulation allows for insight into the behavior of the MLLT under correct and incorrect model specification. This simulation study also highlights shortcomings of independently fit LLT models when correlation exists in the observation or state equations. The data is simulated under three scenarios: 1.) correlation only exists in the observation equation (O), 2.) correlation only exists in the state equation (S), and 3.) correlation exists in both the observation and state equation (OS). The independent LLT, the O MLLT, S MLLT, and OS MLLT are all fit to each of the three data generation processes.

The covariates are randomly generated to mirror the predictors of interest (section \ref{MOI}). There is a time effect, a binary group effect, and a linear continuity point effect. For each simulation, 100 subjects are generated with 10 repeated measurements. The ``true'' linear effects \(\boldsymbol{\beta}\), observation error covariances (\(\Sigma_\varepsilon\)), and underlying state process covariances (\(\Sigma_\eta\)) are denoted below (equations \ref{eq:mod}, \ref{eq:O}, \ref{eq:S}, and \ref{eq:OS}).

The underlying data generation for each of the three simulation scenarios are as follows,

\begin{equation}\label{eq:mod}
\begin{aligned}
\begin{bmatrix}
y_{ij1}\\
y_{ij2}\\
y_{ij3}
\end{bmatrix}
&= \begin{bmatrix}
\alpha_{ij1}\\
\alpha_{ij2}\\
\alpha_{ij3}
\end{bmatrix}
+ 
\begin{bmatrix}
\boldsymbol{x_{ij}\beta_1}\\
\boldsymbol{x_{ij}\beta_2}\\
\boldsymbol{x_{ij}\beta_3} 
\end{bmatrix} +
\begin{bmatrix}
\varepsilon_{ij1}\\
\varepsilon_{ij2}\\
\varepsilon_{ij3}
\end{bmatrix},  
\begin{bmatrix}
\varepsilon_{ij1}\\
\varepsilon_{ij2}\\
\varepsilon_{ij3}
\end{bmatrix} 
\sim N(0, \Sigma_\varepsilon
)\\
\begin{bmatrix}
\alpha_{ij1}\\
\alpha_{ij2}\\
\alpha_{ij3}
\end{bmatrix} & = 
\begin{bmatrix}
\alpha_{i(j-1)1}\\
\alpha_{i(j-1)2}\\
\alpha_{i(j-1)3}
\end{bmatrix} +
\begin{bmatrix}
\eta_{ij1}\\
\eta_{ij2}\\
\eta_{ij3}
\end{bmatrix},
\begin{bmatrix}
\eta_{ij1}\\
\eta_{ij2}\\
\eta_{ij3}
\end{bmatrix} \sim N(0, \delta_{ij} \Sigma_\eta 
)\\
\boldsymbol{\beta} &= \begin{bmatrix} \boldsymbol{\beta_1} & \boldsymbol{\beta_2} &  \boldsymbol{\beta_3} \end{bmatrix} = 
\begin{bmatrix}
4 & -3 & 0\\
2 & 0 & 0\\
1 & 1 & 0
\end{bmatrix}
\end{aligned}
\end{equation}

for \(i \in \{1, 2, ..., 100\}\) and \(j \in \{2, 3,..., 12\}\). The parameters in \(\boldsymbol{\beta}\) were chosen to have no, small, medium, large, and negative effects. For the three different data generation scenarios we utilize differing values of \(\Sigma_\varepsilon\) and \(\Sigma_\eta\).

\hypertarget{o-model}{%
\paragraph{O Model}\label{o-model}}

\begin{equation}\label{eq:O}
\Sigma_\varepsilon = 
\begin{bmatrix}
15 & 2.4 & 1\\
2.4 & 15 & 1\\
1 & 1 & 10
\end{bmatrix},
\Sigma_\eta =
\begin{bmatrix}
5 & 0 & 0\\
0 & 5 & 0\\
0 & 0 & 2
\end{bmatrix}
\end{equation}

\hypertarget{s-model}{%
\paragraph{S Model}\label{s-model}}

\begin{equation}\label{eq:S}
\Sigma_\varepsilon = 
\begin{bmatrix}
15 & 0 & 0\\
0 & 15 & 0\\
0 & 0 & 10
\end{bmatrix}, 
\Sigma_\eta =
\begin{bmatrix}
5 & 3.7 & 0\\
3.7 & 5 & 0\\
0 & 0 & 2
\end{bmatrix}
\end{equation}

\hypertarget{os-model}{%
\paragraph{OS Model}\label{os-model}}

\begin{equation}\label{eq:OS}
\Sigma_\varepsilon = 
\begin{bmatrix}
15 & 2.4 & 1\\
2.4 & 15 & 1\\
1 & 1 & 10
\end{bmatrix}, 
\Sigma_\eta =
\begin{bmatrix}
5 & 3.7 & 0\\
3.7 & 5 & 0\\
0 & 0 & 2
\end{bmatrix}
\end{equation}

The covariance matrices \(\boldsymbol{\Sigma_\varepsilon}\) and \(\boldsymbol{\Sigma_\eta}\) were chosen to approximate values observed when the MLLT models were fit to real data.

For each scenario, the simulations are carried out 1000 times. The most effective model is one that is unbiased, maintains 95\% coverage, and small parameter variance (indicated by small confidence interval length) for the parameters in \(\boldsymbol{\beta}\), \(\boldsymbol{\Sigma_\varepsilon}\), and \(\boldsymbol{\Sigma_\eta}\). Maintaining proper 95\% coverage indicates proper type I error at the level of 0.05. If we can fix type I error, the next step is to minimize type II error which then leads to greater power to detect significant differences. Minimizing type II error will occurs by minimizing the parameter variance if the estimates are unbiased and have proper 95\% coverage. As we are using a Bayesian Gibb's sampling approach, the confidence interval is used to judge parameter variance.

The Bayesian Gibb's sampler is repeated 5000 times with a burn-in of 2000 for each model. This means samples 2001-5000 are used for parameter inference.

\hypertarget{fully-simulated-results}{%
\subsection{Fully Simulated Results}\label{fully-simulated-results}}

The LLT, O, S, and OS models all show unbiasedness and near 95\% coverage in the linear effect parameters in all three simulation scenarios. This occurs despite the LLT, O, and S models having a level of misspecification in the covariance parameters in the different scenarios. In the linear effects there is not a large difference in confidence interval length between the different methods. The O, S, and OS models maintain performace when compared to the LLT with respect to linear effects. However, the primary motivation of the MLLT models are to gain inference on correlation between cognitive tests.

The parameters in \(\Sigma_\varepsilon\) and \(\Sigma_\eta\) vary much more across the data generation processes. When generating from the O model the O and OS estimation maintains unbiased estimates and 95\% coverage. Unsurprisingly, the misspecified S estimation provides erroneous estimates and poor coverage for the covariance matrices. A similar pattern arises when generating from the S model. The correctly specified S and OS models show near unbiasedness and 95\% coverage. The coverage does lack in some, most likely due to identifiability issues, but the estimates are still in a close neighborhood of the correct values. As the primary interest is identifying underlying constructs, and not hypothesis testing, these results are promising.

For the OS data generation processes, the LLT and the S estimation models assume there is not any covariance in the observation error, therefore, do not seek to estimate the non-diagonal values of \(\Sigma_\varepsilon\). Even so, the LLT and S models are fairly accurate in estimating the observation variances. The O estimation model, which does assume observation error covariance, greatly over estimates the covariance parameters. This occurs because the O model assumes no covariance in the state equation, therefore, any correlation in the state equation ends up being allocated to the observation error. Additionally, we see the same principle for the S model in estimating \(\Sigma_\eta\). The covariance parameters of \(\Sigma_\eta\) are inflated as model S is assuming correlation truly occurring in \(\Sigma_\varepsilon\) is actually occurring in the underlying cognitive process. The OS model, which is correctly specified, unsurprisingly accurately estimates the \(\Sigma_\varepsilon\) and \(\Sigma_\eta\).

The OS model estimates \(K(K-1)/2\) more parameters than the O and S models. Even with the extra parameters, the OS model estimation performed as well as the correctly specified O and S models respectively. However, if O or S are misspecified it can lead to miscalculation in the covariance matrices. The OS model is much more robust in terms of handling different observation error and cognitive process correlation.

Shortcomings are also blatantly evident as the LLT provides no observation error or cognitive process correlation estimation. The O and S models do provide some insight into the inter-relatedness between cognition tests, but the OS provides the most descriptive form of the correlations. With the added covariance estimation benefits of the OS MLLT, it perform just as well as the LLT in modeling linear effects.

\hypertarget{o-model-1}{%
\subsubsection{O Model}\label{o-model-1}}

\begin{table}

\caption{\label{tab:unnamed-chunk-9}Linear effect coverage percentage.}
\centering
\begin{tabular}[t]{llrllll}
\toprule
Test & Variable & Beta & LLT & O & S & OS\\
\midrule
Y1 & X1 & 4 & 96.4\% & 96.5\% & 96.9\% & 96.3\%\\
Y1 & X2 & 2 & 96.5\% & 96.4\% & 95.8\% & 95.7\%\\
Y1 & X3 & 1 & 95.3\% & 95.3\% & 95.5\% & 95.4\%\\
Y2 & X1 & -3 & 94\% & 94.8\% & 94.5\% & 94.3\%\\
Y2 & X2 & 0 & 95.5\% & 95.4\% & 95.2\% & 96.2\%\\
\addlinespace
Y2 & X3 & 1 & 93.7\% & 93.2\% & 94.2\% & 93.8\%\\
Y3 & X1 & 0 & 95.7\% & 95\% & 95.4\% & 95.2\%\\
Y3 & X2 & 0 & 94.8\% & 94.9\% & 95\% & 95.6\%\\
Y3 & X3 & 0 & 95\% & 95\% & 94.9\% & 94.7\%\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}
\centering
\includegraphics{FullSimulation_files/figure-latex/unnamed-chunk-10-1.pdf}
\caption{\label{fig:unnamed-chunk-10}Bias and Estimate Variability}
\end{figure}

\textbackslash begin\{table\}

\textbackslash caption\{\label{tab:unnamed-chunk-11}Covariance estimate (coverage \%)\}
\centering

\begin{tabular}[t]{ccccccc}
\toprule
 & Parameter & True value & LLT & O & S & OS\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{Observation Error}}\\
\hspace{1em} & 1,1 & 15 & 14.909 (95\%) & 14.919 (95.1\%) & 14.688 (92.8\%) & 14.95 (94.8\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 2.4 & - & 2.371 (95.3\%) & - & 2.425 (94.1\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 15 & 14.892 (94.4\%) & 14.903 (94.9\%) & 14.668 (93.4\%) & 14.927 (94.6\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 1 & - & 0.99 (95.6\%) & - & 1.027 (95.6\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 1 & - & 0.988 (95.2\%) & - & 1.008 (94.7\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 10 & 10.056 (95.1\%) & 10.063 (94.5\%) & 10.021 (94.7\%) & 10.093 (95.1\%)\\
\cmidrule{1-7}
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{State Process}}\\
\hspace{1em} & 1,1 & 5 & 4.89 (93.5\%) & 4.969 (94.8\%) & 5.206 (93.8\%) & 4.985 (94.5\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 0 & - & 0 (-) & - & -0.071 (93.9\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 5 & 4.887 (94.8\%) & 4.964 (95.2\%) & 5.205 (95.5\%) & 4.988 (95.1\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 0 & - & 0 (-) & - & -0.042 (94.2\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 0 & - & 0 (-) & - & -0.021 (93.3\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 2 & 1.893 (92\%) & 1.932 (93.6\%) & 1.973 (93\%) & 1.932 (93.4\%)\\
\bottomrule
\end{tabular}

\textbackslash end\{table\}

\hypertarget{s-model-1}{%
\subsubsection{S Model}\label{s-model-1}}

\begin{table}

\caption{\label{tab:unnamed-chunk-13}Linear effect coverage percentage.}
\centering
\begin{tabular}[t]{llrllll}
\toprule
Test & Variable & Beta & LLT & O & S & OS\\
\midrule
Y1 & X1 & 4 & 95.4\% & 95.6\% & 95.7\% & 95.9\%\\
Y1 & X2 & 2 & 94.6\% & 95.1\% & 95\% & 95.6\%\\
Y1 & X3 & 1 & 95.9\% & 95.7\% & 95.8\% & 95.7\%\\
Y2 & X1 & -3 & 95.7\% & 96.5\% & 95.5\% & 96.1\%\\
Y2 & X2 & 0 & 94.1\% & 94.3\% & 94.8\% & 95.1\%\\
\addlinespace
Y2 & X3 & 1 & 95.3\% & 95.7\% & 95.5\% & 95.7\%\\
Y3 & X1 & 0 & 94.5\% & 94.8\% & 94.6\% & 94.5\%\\
Y3 & X2 & 0 & 95\% & 95.4\% & 94.9\% & 95.8\%\\
Y3 & X3 & 0 & 93.8\% & 94.2\% & 93.9\% & 93.8\%\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}
\centering
\includegraphics{FullSimulation_files/figure-latex/unnamed-chunk-14-1.pdf}
\caption{\label{fig:unnamed-chunk-14}Bias and Estimate Variability}
\end{figure}

\textbackslash begin\{table\}

\textbackslash caption\{\label{tab:unnamed-chunk-15}Covariance estimate (coverage \%)\}
\centering

\begin{tabular}[t]{ccccccc}
\toprule
 & Parameter & True value & LLT & O & S & OS\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{Observation Error}}\\
\hspace{1em} & 1,1 & 15 & 14.866 (94.9\%) & 15.248 (94.9\%) & 15.147 (93.8\%) & 15.065 (93.5\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 0 & - & 2.436 (2.9\%) & - & -0.387 (90.4\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 15 & 14.908 (95\%) & 15.293 (93.5\%) & 15.18 (93.6\%) & 15.092 (93.5\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 0 & - & 0.012 (95.9\%) & - & 0.006 (95.5\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 0 & - & -0.02 (95.2\%) & - & -0.033 (94.6\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 10 & 10.06 (94.5\%) & 10.064 (94.8\%) & 10.087 (94.8\%) & 10.102 (94.7\%)\\
\cmidrule{1-7}
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{State Process}}\\
\hspace{1em} & 1,1 & 5 & 4.879 (93.2\%) & 4.59 (90.8\%) & 4.803 (92.2\%) & 4.94 (93\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 3.714 & - & 0 (0\%) & - & 3.98 (91.8\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 5 & 4.899 (93.7\%) & 4.606 (90.2\%) & 4.838 (91.3\%) & 4.977 (91.1\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 0 & - & 0 (-) & - & 0.015 (93.5\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 0 & - & 0 (-) & - & 0.015 (93.3\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 2 & 1.89 (92.7\%) & 1.932 (93.7\%) & 1.916 (92.2\%) & 1.928 (92.7\%)\\
\bottomrule
\end{tabular}

\textbackslash end\{table\}

\hypertarget{os-model-1}{%
\subsubsection{OS Model}\label{os-model-1}}

\begin{table}

\caption{\label{tab:unnamed-chunk-17}Linear effect coverage percentage.}
\centering
\begin{tabular}[t]{llrllll}
\toprule
Test & Variable & Beta & LLT & O & S & OS\\
\midrule
Y1 & X1 & 4 & 96.2\% & 94.8\% & 96.8\% & 96.1\%\\
Y1 & X2 & 2 & 94.6\% & 93.4\% & 95.5\% & 94.5\%\\
Y1 & X3 & 1 & 95.2\% & 94.1\% & 95.8\% & 95\%\\
Y2 & X1 & -3 & 95\% & 94.4\% & 95.8\% & 95.7\%\\
Y2 & X2 & 0 & 94.5\% & 93.1\% & 95.9\% & 95.2\%\\
\addlinespace
Y2 & X3 & 1 & 94.9\% & 94\% & 96.8\% & 96.4\%\\
Y3 & X1 & 0 & 95.7\% & 96.2\% & 96\% & 95.7\%\\
Y3 & X2 & 0 & 95\% & 94.7\% & 94.9\% & 95.2\%\\
Y3 & X3 & 0 & 94.5\% & 94.8\% & 94.9\% & 94.9\%\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}
\centering
\includegraphics{FullSimulation_files/figure-latex/unnamed-chunk-18-1.pdf}
\caption{\label{fig:unnamed-chunk-18}Bias and Estimate Variability}
\end{figure}

\textbackslash begin\{table\}

\textbackslash caption\{\label{tab:unnamed-chunk-19}Covariance estimate (coverage \%)\}
\centering

\begin{tabular}[t]{ccccccc}
\toprule
 & Parameter & True value & LLT & O & S & OS\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{Observation Error}}\\
\hspace{1em} & 1,1 & 15 & 14.964 (94.4\%) & 15.752 (88.2\%) & 14.273 (86.7\%) & 15.075 (94.3\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 2.4 & - & 4.976 (2.4\%) & - & 2.14 (91.7\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 15 & 14.948 (94.1\%) & 15.733 (87.9\%) & 14.248 (85.1\%) & 15.066 (93.8\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 1 & - & 0.997 (94.6\%) & - & 0.979 (94.2\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 1 & - & 1.008 (94.8\%) & - & 0.997 (92.6\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 10 & 10.021 (93.7\%) & 10.021 (93.5\%) & 9.988 (93.7\%) & 10.056 (93.1\%)\\
\cmidrule{1-7}
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{State Process}}\\
\hspace{1em} & 1,1 & 5 & 4.835 (94\%) & 4.168 (78\%) & 5.776 (82.8\%) & 4.941 (94.2\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,2 & 3.714 & - & 0 (0\%) & - & 3.891 (93.7\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,2 & 5 & 4.849 (92.4\%) & 4.183 (78.9\%) & 5.8 (82\%) & 4.952 (92.7\%)\\
\cmidrule{2-7}
\hspace{1em} & 1,3 & 0 & - & 0 (-) & - & -0.009 (93.8\%)\\
\cmidrule{2-7}
\hspace{1em} & 2,3 & 0 & - & 0 (-) & - & -0.015 (93.9\%)\\
\cmidrule{2-7}
\hspace{1em} & 3,3 & 2 & 1.894 (92.6\%) & 1.943 (93.8\%) & 1.977 (93\%) & 1.939 (93\%)\\
\bottomrule
\end{tabular}

\textbackslash end\{table\}

\end{document}
